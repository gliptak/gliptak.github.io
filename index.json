[{"authors":["gliptak"],"categories":null,"content":"Hands-on software architect working as an application architect, integration architect, and enterprise architect in various industries. Experienced in Microservices Architectures, Service-Based Architectures, and Service-Oriented Architectures. Conference speaker and trainer. Keeping coding skills sharp as an open source enthusiast.\n","date":1639341171,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1639341171,"objectID":"6a5735510cbd32c2a406ca9838ee6e34","permalink":"https://gliptak.github.io/authors/gliptak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/gliptak/","section":"authors","summary":"Hands-on software architect working as an application architect, integration architect, and enterprise architect in various industries. Experienced in Microservices Architectures, Service-Based Architectures, and Service-Oriented Architectures. Conference speaker and trainer. Keeping coding skills sharp as an open source enthusiast.","tags":null,"title":"Gábor Lipták","type":"authors"},{"authors":["Gábor Lipták"],"categories":[],"content":"GraphQL API allows for query and mutation (update) operations which can be executed in GitHub\u0026rsquo;s GraphQL Explorer Below example creates a PR. First, find the repository id:\n{ repository(owner: \u0026#34;gliptak\u0026#34;, name: \u0026#34;githubapitest1\u0026#34;) { id } } The repository id to be used to create the pull request:\n{ \u0026#34;data\u0026#34;: { \u0026#34;repository\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;R_kgDOGS1otA\u0026#34; } } } The mutation (update) below creates a new PR from an existing branch (additional details could have been submitted):\nmutation { createPullRequest(input: { repositoryId: \u0026#34;R_kgDOGS1otA\u0026#34; title: \u0026#34;my PR\u0026#34;, baseRefName: \u0026#34;master\u0026#34;, headRefName: \u0026#34;patch-1\u0026#34;}) { pullRequest { url } } } Resulting JSON displays the URL of PR created:\n{ \u0026#34;data\u0026#34;: { \u0026#34;createPullRequest\u0026#34;: { \u0026#34;pullRequest\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/gliptak/githubapitest1/pull/1\u0026#34; } } } } At this point @export directive allowing to chain variables between queries is under consideration so variable substitution has to happen manually or programatically.\n","date":1639341171,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639341171,"objectID":"87939a8299124f9335c165db7e9cf846","permalink":"https://gliptak.github.io/post/github_graphql_newpr/","publishdate":"2021-12-12T20:32:51Z","relpermalink":"/post/github_graphql_newpr/","section":"post","summary":"GraphQL API allows for query and mutation (update) operations which can be executed in GitHub\u0026rsquo;s GraphQL Explorer Below example creates a PR. First, find the repository id:\n{ repository(owner: \u0026#34;gliptak\u0026#34;, name: \u0026#34;githubapitest1\u0026#34;) { id } } The repository id to be used to create the pull request:\n{ \u0026#34;data\u0026#34;: { \u0026#34;repository\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;R_kgDOGS1otA\u0026#34; } } } The mutation (update) below creates a new PR from an existing branch (additional details could have been submitted):","tags":["Github","GraphQL"],"title":"Github Create PR with GraphQL","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"While Github GraphQL offers detailed documentation and an API Explorer, it doesn\u0026rsquo;t have (Python) code samples. Below is a basic GQL example. The query can be developed/tested in Explorer\nfrom gql import gql, Client from gql.transport.requests import RequestsHTTPTransport import click @click.command() @click.option(\u0026#39;--githubtoken\u0026#39;, envvar=\u0026#34;GITHUB_TOKEN\u0026#34;, prompt=True, hide_input=True, help=\u0026#39;Github token\u0026#39;) @click.option(\u0026#39;--owner\u0026#39;, help=\u0026#39;Repository owner\u0026#39;, required=True) @click.option(\u0026#39;--repository\u0026#39;, help=\u0026#39;Repository name\u0026#39;, required=True) def gh_query_repo(githubtoken, owner, repository): transport=RequestsHTTPTransport( url=\u0026#39;https://api.github.com/graphql\u0026#39;, use_json=True, headers={ \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {githubtoken}\u0026#34;, }, #verify=False, retries=3, ) client = Client( transport=transport, fetch_schema_from_transport=True, ) query_repo = \u0026#39;\u0026#39;\u0026#39; query Repository($owner: String!, $repo: String!) { repository(name: $repo, owner: $owner) { id } } \u0026#39;\u0026#39;\u0026#39; // [^1] result = client.execute( gql(query_repo), variable_values={ \u0026#34;owner\u0026#34;: owner, \u0026#34;repo\u0026#34;: repository, } ) repositoryId = result[\u0026#39;repository\u0026#39;][\u0026#39;id\u0026#39;] print(repositoryId) if __name__ == \u0026#34;__main__\u0026#34;: gh_query_repo() ","date":1635697121,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635697121,"objectID":"28d2493e75db1483c2648dff3f66c4bd","permalink":"https://gliptak.github.io/post/github_graphql_example/","publishdate":"2021-10-31T16:18:41Z","relpermalink":"/post/github_graphql_example/","section":"post","summary":"While Github GraphQL offers detailed documentation and an API Explorer, it doesn\u0026rsquo;t have (Python) code samples. Below is a basic GQL example. The query can be developed/tested in Explorer\nfrom gql import gql, Client from gql.transport.requests import RequestsHTTPTransport import click @click.command() @click.option(\u0026#39;--githubtoken\u0026#39;, envvar=\u0026#34;GITHUB_TOKEN\u0026#34;, prompt=True, hide_input=True, help=\u0026#39;Github token\u0026#39;) @click.option(\u0026#39;--owner\u0026#39;, help=\u0026#39;Repository owner\u0026#39;, required=True) @click.option(\u0026#39;--repository\u0026#39;, help=\u0026#39;Repository name\u0026#39;, required=True) def gh_query_repo(githubtoken, owner, repository): transport=RequestsHTTPTransport( url=\u0026#39;https://api.github.com/graphql\u0026#39;, use_json=True, headers={ \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {githubtoken}\u0026#34;, }, #verify=False, retries=3, ) client = Client( transport=transport, fetch_schema_from_transport=True, ) query_repo = \u0026#39;\u0026#39;\u0026#39; query Repository($owner: String!","tags":["Github","GraphQL"],"title":"Github GraphQL Example","type":"post"},{"authors":[],"categories":[],"content":"If the CloudFormation create has an error, the CloudFormation doesn\u0026rsquo;t roll back so it has to be deleted and recreated. To avoid multiple initial create/delete, the best approach is to use a null CloudFormation. An example is below:\nAWSTemplateFormatVersion: 2010-09-09 Description: CloudFormation Starter Conditions: Never: !Equals [ a, b ] Resources: NullResource: Type: Custom::Null Condition: Never ","date":1625331049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625331049,"objectID":"fd74fde5966b04098fed11fc71037a11","permalink":"https://gliptak.github.io/post/aws_cloudformation_starter/","publishdate":"2021-07-03T16:50:49Z","relpermalink":"/post/aws_cloudformation_starter/","section":"post","summary":"If the CloudFormation create has an error, the CloudFormation doesn\u0026rsquo;t roll back so it has to be deleted and recreated. To avoid multiple initial create/delete, the best approach is to use a null CloudFormation. An example is below:\nAWSTemplateFormatVersion: 2010-09-09 Description: CloudFormation Starter Conditions: Never: !Equals [ a, b ] Resources: NullResource: Type: Custom::Null Condition: Never ","tags":["AWS","CloudFormation"],"title":"AWS CloudFormation Starter/`null` Template","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"While the actual application code for many lambda functions might be small, in many (data science) usecases libraries used and to be packaged together push over the deployment package limit of 50 MB compressed. Container packaging to the rescue.\nA sample Dockerfile installing SageMaker Python SDK\nARG WORK_DIR=\u0026quot;/home/app/\u0026quot; FROM public.ecr.aws/lambda/python:3.8 ARG WORK_DIR RUN pip install wheel sagemaker COPY main.py . WORKDIR ${WORK_DIR} CMD [\u0026quot;main.handler\u0026quot;] and corresponding main.py\nimport sagemaker import sys def handler(event, context): print(sys.version) print(f\u0026#34;sagemaker {sagemaker.__version__}\u0026#34;) return { \u0026#39;success\u0026#39;: True } As an added bonus, above image can be built and tested locally:\ndocker build -t sagemaker-python-sdk-demo:latest . curl -XPOST \u0026#34;http://localhost:9002/2015-03-31/functions/function/invocations\u0026#34; -d \u0026#39;{}\u0026#39; {\u0026#34;success\u0026#34;: true} docker run --rm -p 9002:8080 sagemaker-python-sdk-demo:latest time=\u0026#34;2021-06-28T02:12:34.914\u0026#34; level=info msg=\u0026#34;exec \u0026#39;/var/runtime/bootstrap\u0026#39; (cwd=/home/app, handler=)\u0026#34; time=\u0026#34;2021-06-28T02:13:21.485\u0026#34; level=info msg=\u0026#34;extensionsDisabledByLayer(/opt/disable-extensions-jwigqn8j) -\u0026gt; stat /opt/disable-extensions-jwigqn8j: no such file or directory\u0026#34; time=\u0026#34;2021-06-28T02:13:21.485\u0026#34; level=warning msg=\u0026#34;Cannot list external agents\u0026#34; error=\u0026#34;open /opt/extensions: no such file or directory\u0026#34; START RequestId: 0265665a-d04e-4f29-b87d-472f3e7001ae Version: $LATEST 3.8.10 (default, Jun 21 2021, 07:32:26) [GCC 7.3.1 20180712 (Red Hat 7.3.1-12)] sagemaker 2.47.0 END RequestId: 0265665a-d04e-4f29-b87d-472f3e7001ae REPORT RequestId: 0265665a-d04e-4f29-b87d-472f3e7001ae\tInit Duration: 0.45 ms\tDuration: 1025.09 ms\tBilled Duration: 1100 ms\tMemory Size: 3008 MB\tMax Memory Used: 3008 MB   Note the memory consumed above\n  Review Amazon ECR Registry upload and deployment documentation\n","date":1624772861,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624772861,"objectID":"08e1f117ca8e8a329a6b522e185fd137","permalink":"https://gliptak.github.io/post/aws_lambda_container/","publishdate":"2021-06-27T01:47:41-04:00","relpermalink":"/post/aws_lambda_container/","section":"post","summary":"While the actual application code for many lambda functions might be small, in many (data science) usecases libraries used and to be packaged together push over the deployment package limit of 50 MB compressed. Container packaging to the rescue.\nA sample Dockerfile installing SageMaker Python SDK\nARG WORK_DIR=\u0026quot;/home/app/\u0026quot; FROM public.ecr.aws/lambda/python:3.8 ARG WORK_DIR RUN pip install wheel sagemaker COPY main.py . WORKDIR ${WORK_DIR} CMD [\u0026quot;main.handler\u0026quot;] and corresponding main.py\nimport sagemaker import sys def handler(event, context): print(sys.","tags":["AWS","Lambda","Docker"],"title":"Packaging AWS Lambda functions with large dependencies as containers","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"Jupyterhub doesn\u0026rsquo;t seem to have complete instructions available on simply running an instance under Docker with a number of issues, Stackoverflow questions asking for clarifications. These are my quick notes:\nAs the Docker image name indicates, this is singleuser instance preconfigured for user jovyan. Run below command in directory with your notebooks\ndocker run --rm -p 8000:8000 -d -v `pwd`:/home/jovyan/work --name jupyterhub jupyterhub/singleuser jupyterhub There doesn\u0026rsquo;t seem to be (default) password set for jovyan user, so at this point you cannot login into the GUI. Set password for jovyan\ndocker exec --user root -it jupyterhub bash # passwd jovyan New password: Retype new password: passwd: password updated successfully # exit exit  ℹ️ Above shell command can also be used to install system packages and pip install Python libraries. Please note that additional installs will not persist beyond stopping this current instance\n After completing above steps, login to Jupyterhub at http://localhost:8000/user/jovyan/tree/work\nTo cleanup running instance\ndocker stop jupyterhub ","date":1608412025,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608412025,"objectID":"b3b5398c0f3e9d4c9bead468f59e4f7a","permalink":"https://gliptak.github.io/post/jupyterhub_docker/","publishdate":"2020-12-19T17:07:05-04:00","relpermalink":"/post/jupyterhub_docker/","section":"post","summary":"Jupyterhub doesn\u0026rsquo;t seem to have complete instructions available on simply running an instance under Docker with a number of issues, Stackoverflow questions asking for clarifications. These are my quick notes:\nAs the Docker image name indicates, this is singleuser instance preconfigured for user jovyan. Run below command in directory with your notebooks\ndocker run --rm -p 8000:8000 -d -v `pwd`:/home/jovyan/work --name jupyterhub jupyterhub/singleuser jupyterhub There doesn\u0026rsquo;t seem to be (default) password set for jovyan user, so at this point you cannot login into the GUI.","tags":["Python","Jupyter","Docker"],"title":"Running Jupyterhub Docker","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"Splunk can be extended with custom inputs written in Python. In order to connect to Splunk services, code has to be configured and use a session token. Here is a basic setup emitting records with kvstore names\n#!/usr/bin/env python import splunklib.client as client import sys import datetime as dt def generate(session_key): service = client.connect(token = session_key) for collection in service.kvstore: ts = dt.datetime.now(tz=dt.timezone.utc).isoformat() print(f'{ts}, collection=\u0026quot;{collection.name}\u0026quot;') if __name__ == \u0026quot;__main__\u0026quot;: session_key = sys.stdin.read() generate(session_key) and the corresponding default/inputs.conf\n[script://./bin/listkvstores.py] interval = 300 disabled = False passAuth = nobody kvstore access uses user nobody, other Splunk services might need a different user configured.\n","date":1604157450,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604157450,"objectID":"d450bc519a0de118b5104fdb186558ce","permalink":"https://gliptak.github.io/post/splunk_custom_input_session/","publishdate":"2020-10-31T11:17:30-04:00","relpermalink":"/post/splunk_custom_input_session/","section":"post","summary":"Splunk can be extended with custom inputs written in Python. In order to connect to Splunk services, code has to be configured and use a session token. Here is a basic setup emitting records with kvstore names\n#!/usr/bin/env python import splunklib.client as client import sys import datetime as dt def generate(session_key): service = client.connect(token = session_key) for collection in service.kvstore: ts = dt.datetime.now(tz=dt.timezone.utc).isoformat() print(f'{ts}, collection=\u0026quot;{collection.name}\u0026quot;') if __name__ == \u0026quot;__main__\u0026quot;: session_key = sys.","tags":["Splunk","Python"],"title":"Splunk custom input with session","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"Many AWS customers skip initial planning steps and don\u0026rsquo;t establish infrastructure-as-code scripting practices initially necessitating querying and cleaning up resources to avoid billing charges.\nAWS tooling   AWS Cost Explorer  AWS Billing Console  AWS Tag Editor select all regions, all resource types and uncheck tags  The open source community developed a number of tools\nList all AWS resources   aws_list_all command line  awsls  AWSRetriever desktop  aws-inventory command line and GUI  Filtered delete   aws-nuke extensive filtering  cloud-nuke filtering by region, age, resourcetype is available  ","date":1604153850,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604153850,"objectID":"bf64f210232438d9fa579da669977452","permalink":"https://gliptak.github.io/post/aws_account_cleanup/","publishdate":"2020-10-31T10:17:30-04:00","relpermalink":"/post/aws_account_cleanup/","section":"post","summary":"Many AWS customers skip initial planning steps and don\u0026rsquo;t establish infrastructure-as-code scripting practices initially necessitating querying and cleaning up resources to avoid billing charges.\nAWS tooling   AWS Cost Explorer  AWS Billing Console  AWS Tag Editor select all regions, all resource types and uncheck tags  The open source community developed a number of tools\nList all AWS resources   aws_list_all command line  awsls  AWSRetriever desktop  aws-inventory command line and GUI  Filtered delete   aws-nuke extensive filtering  cloud-nuke filtering by region, age, resourcetype is available  ","tags":["AWS"],"title":"AWS Account Cleanup","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"For a number of uses including generating IAM roles and various policies, lambda code might require access to current account id and region. Here is a code snippet on how to acquire those values:\nimport json import logging import boto3 logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): logger.info(json.dumps(event)) account_id = boto3.client('sts').get_caller_identity().get('Account') # use a client which is region based logs_client = boto3.client('logs') region_name = logs_client.meta.region_name logger.info(f\u0026quot;{account_id}:{region_name}\u0026quot;) ","date":1601677945,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601677945,"objectID":"05dd4394a5c6ae18c1171d824577d283","permalink":"https://gliptak.github.io/post/aws_lambda_accountregion/","publishdate":"2020-10-02T18:32:25-04:00","relpermalink":"/post/aws_lambda_accountregion/","section":"post","summary":"For a number of uses including generating IAM roles and various policies, lambda code might require access to current account id and region. Here is a code snippet on how to acquire those values:\nimport json import logging import boto3 logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): logger.info(json.dumps(event)) account_id = boto3.client('sts').get_caller_identity().get('Account') # use a client which is region based logs_client = boto3.client('logs') region_name = logs_client.meta.region_name logger.info(f\u0026quot;{account_id}:{region_name}\u0026quot;) ","tags":["AWS","Lambda"],"title":"AWS Lambda Lookup AccountId and Region","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"EC2 Instance Connect is somewhat overlooked functionality improving security of EC2 logins. During configuration, the default instance user is assigned a public key so it\u0026rsquo;s private pair can be used to connect to the instance. The private key tends to be shared within support teams and logins can no longer be attributed to an individual. EC2 instance Connect runs and logs connect commands as the individual user and obeys user\u0026rsquo;s permission.\nOnto the steps. Run:\n aws ec2-instance-connect send-ssh-public-key --instance-id i-0123abc --instance-os-user ec2-user --availability-zone us-east-1b --ssh-public-key file://id_rsa.pub Substitute the right values for your instance, they can be found on the AWS Console or queried running aws ec2 describe-instances.\nAfter above command successful, use (routable) FQDN/IP to connect to your instance (some operating systems use a different default user):\nssh ec2-user@1.2.3.4 The functionality also available from the AWS Console:\nThis activity is logged by CloudTrail although the shell commands still being run as the default instance user.\nWhile EC2 Instance Connect offers less functionality as compared to other tooling like AWS Systems Manager SSM or a proper Privileged Access Management (PAM) tool, it requires no additional configuration on the instance.\n","date":1590765450,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590765450,"objectID":"b1079a1a74e0bc4679793d50b8fdac44","permalink":"https://gliptak.github.io/post/aws_ec2instanceconnect/","publishdate":"2020-05-29T11:17:30-04:00","relpermalink":"/post/aws_ec2instanceconnect/","section":"post","summary":"EC2 Instance Connect is somewhat overlooked functionality improving security of EC2 logins. During configuration, the default instance user is assigned a public key so it\u0026rsquo;s private pair can be used to connect to the instance. The private key tends to be shared within support teams and logins can no longer be attributed to an individual. EC2 instance Connect runs and logs connect commands as the individual user and obeys user\u0026rsquo;s permission.","tags":["AWS"],"title":"AWS EC2 Instance Connect","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"While I found a number of examples for generating signed upload S3 URLs, there didn\u0026rsquo;t seem to be examples with the basics.\nAfter substituting the name for your bucket, file name and expiry desired, run below code to generate the URL:\nimport boto3 if __name__ == \u0026quot;__main__\u0026quot;: s3_client = boto3.client('s3') response = s3_client.generate_presigned_url( ClientMethod='put_object', Params={\u0026quot;Bucket\u0026quot;: \u0026quot;mybucket\u0026quot;, \u0026quot;Key\u0026quot;: \u0026quot;file.pdf\u0026quot;}, ExpiresIn=48*60*60, HttpMethod=\u0026quot;PUT\u0026quot;) print(response) To upload from command line run below (substituting URL from previous section):\ncurl \u0026quot;https://mybucket.s3.amazonaws.com/file.pdf?AWSAccessKeyId=AKIAWR6H3WAK6NZTVBJP\u0026amp;Signature=CkFT8z3KK8zznNSZ6sOZryFHQTM%3D\u0026amp;Expires=1584826340\u0026quot; --upload-file file.pdf ","date":1584653545,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584653545,"objectID":"a34c5fdd19f61356bf2afe47d3b54fcf","permalink":"https://gliptak.github.io/post/aws_s3_signed_url/","publishdate":"2020-03-19T17:32:25-04:00","relpermalink":"/post/aws_s3_signed_url/","section":"post","summary":"While I found a number of examples for generating signed upload S3 URLs, there didn\u0026rsquo;t seem to be examples with the basics.\nAfter substituting the name for your bucket, file name and expiry desired, run below code to generate the URL:\nimport boto3 if __name__ == \u0026quot;__main__\u0026quot;: s3_client = boto3.client('s3') response = s3_client.generate_presigned_url( ClientMethod='put_object', Params={\u0026quot;Bucket\u0026quot;: \u0026quot;mybucket\u0026quot;, \u0026quot;Key\u0026quot;: \u0026quot;file.pdf\u0026quot;}, ExpiresIn=48*60*60, HttpMethod=\u0026quot;PUT\u0026quot;) print(response) To upload from command line run below (substituting URL from previous section):","tags":["AWS","S3"],"title":"AWS S3 Signed Upload URL Basics","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"When AWS infrastructure configured in \u0026ldquo;traditional\u0026rdquo; compute/storage/network style, identifying, referencing and patching AMIs in all regions in use is crucial. Cloudformation has a way to redirect AMI references through SSM Parameter Store.\nThis represents a tradeoff, as recreating the Cloudformation stack might pickup the next (patched) AMI hence it is no longer immutable. But resulting state is similar to externally patched Linux/Windows images which also cannot be recreated by simply redeploying Cloudformation.\nTh Cloudformation syntax as follows. AmiId can point to both AWS and customer published values:\nAWSTemplateFormatVersion: '2010-09-09' Parameters: AmiId: Type: AWS::SSM::Parameter::Value\u0026lt;AWS::EC2::Image::Id\u0026gt; Default: /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-ebs Resources: Instance: Type: AWS::EC2::Instance Properties: ImageId: !Ref AmiId At the time of this posting, here are some AWS maintained AMIs:\naws ssm get-parameters-by-path --path /aws/service/ami-amazon-linux-latest | jq \u0026quot;.Parameters[].Name\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-hvm-x86_64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-hvm-x86_64-gp2\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-hvm-x86_64-s3\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-minimal-hvm-x86_64-s3\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-minimal-pv-x86_64-s3\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-pv-x86_64-s3\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-arm64-gp2\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn2-ami-minimal-hvm-arm64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-minimal-hvm-x86_64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-minimal-pv-x86_64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn-ami-pv-x86_64-ebs\u0026quot; \u0026quot;/aws/service/ami-amazon-linux-latest/amzn2-ami-minimal-hvm-x86_64-ebs\u0026quot; aws ssm get-parameters-by-path --path /aws/service/ami-windows-latest | jq \u0026quot;.Parameters[].Name\u0026quot; | grep \u0026quot;English\u0026quot; | grep \u0026quot;\\-2019\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2017_Web\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2016_SP2_Standard\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2016_SP2_Web\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-HyperV\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Core-Base\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Core-ContainersLatest\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2017_Express\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2016_SP2_Express\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-Base\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2017_Standard\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-ContainersLatest\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2017_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-SQL_2016_SP2_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Tesla\u0026quot; \u0026quot;/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-ECS_Optimized\u0026quot; And some \u0026ldquo;oddballs\u0026rdquo;\naws ssm get-parameters-by-path --path /aws/service/ami-windows-latest | jq \u0026quot;.Parameters[].Name\u0026quot; | grep -v Windows \u0026quot;/aws/service/ami-windows-latest/amzn2-ami-hvm-2.0.20190313-x86_64-gp2-SQL_2017_Express\u0026quot; \u0026quot;/aws/service/ami-windows-latest/RHEL-7.6_HVM_GA-20181017-x86_64-0-Hourly2-GP2-SQL_2017_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-bionic-18.04-amd64-server-20180522-dotnetcore\u0026quot; \u0026quot;/aws/service/ami-windows-latest/amzn2-ami-hvm-2.0.20180622.1-x86_64-gp2-dotnetcore\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20190212-SQL_2017_Web\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20180306-SQL_2017_Express\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20180306-SQL_2017_Standard\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20180306-SQL_2017_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20180306-SQL_2017_Web\u0026quot; \u0026quot;/aws/service/ami-windows-latest/amzn2-ami-hvm-2.0.20190313-x86_64-gp2-SQL_2017_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20190212-SQL_2017_Enterprise\u0026quot; \u0026quot;/aws/service/ami-windows-latest/amzn2-ami-hvm-2.0.20190313-x86_64-gp2-SQL_2017_Web\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20190212-SQL_2017_Express\u0026quot; \u0026quot;/aws/service/ami-windows-latest/amzn2-ami-hvm-2.0.20190313-x86_64-gp2-SQL_2017_Standard\u0026quot; \u0026quot;/aws/service/ami-windows-latest/ubuntu-xenial-16.04-amd64-server-20190212-SQL_2017_Standard\u0026quot; ","date":1568251945,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568251945,"objectID":"fdb02ad00c12ea24c0416ee7a6afa29f","permalink":"https://gliptak.github.io/post/aws_ssm_ami/","publishdate":"2019-09-11T21:32:25-04:00","relpermalink":"/post/aws_ssm_ami/","section":"post","summary":"When AWS infrastructure configured in \u0026ldquo;traditional\u0026rdquo; compute/storage/network style, identifying, referencing and patching AMIs in all regions in use is crucial. Cloudformation has a way to redirect AMI references through SSM Parameter Store.\nThis represents a tradeoff, as recreating the Cloudformation stack might pickup the next (patched) AMI hence it is no longer immutable. But resulting state is similar to externally patched Linux/Windows images which also cannot be recreated by simply redeploying Cloudformation.","tags":["AWS","Cloudformation"],"title":"AWS Cloudformation Referencing AMIs Using SSM Parameter Store","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"Many AWS customers take advantage of AWS Organizations to organize and secure their workloads. In many cases, users login into their master account and configure permissions allowing to switch to member accounts in the Console. The same permissions can be used for AWS CLI.\nIn this example below, a single AWS Access Key has to be generated (and rotated) in the master account and it can be used to switch to test/2222222 and production/3333333 accounts using the CrossAccountAccessRole already configured for switching in the Console.\n[master] aws_access_key_id = AKIZZZZZZZZZZZZ aws_secret_access_key = a78594065069565 [test] role_arn = arn:aws:iam::2222222:role/CrossAccountAccessRole source_profile = master [production] role_arn = arn:aws:iam::3333333:role/CrossAccountAccessRole source_profile = master ","date":1567905450,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567905450,"objectID":"428eab21cae0e5a1776a0d06f2d93064","permalink":"https://gliptak.github.io/post/aws_organization_cli/","publishdate":"2019-09-07T21:17:30-04:00","relpermalink":"/post/aws_organization_cli/","section":"post","summary":"Many AWS customers take advantage of AWS Organizations to organize and secure their workloads. In many cases, users login into their master account and configure permissions allowing to switch to member accounts in the Console. The same permissions can be used for AWS CLI.\nIn this example below, a single AWS Access Key has to be generated (and rotated) in the master account and it can be used to switch to test/2222222 and production/3333333 accounts using the CrossAccountAccessRole already configured for switching in the Console.","tags":["AWS"],"title":"AWS Organizations CLI","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"While this below code is simple, it uses two important approaches:\n utilizes a Requests Session to keep Siteminder login cookies/headers it has a two step load, allowing to fill out the Siteminder form  import requests if __name__ == \u0026#34;__main__\u0026#34;: mysite = \u0026#39;http://mysite/\u0026#39; credentials = {\u0026#39;USER\u0026#39;: \u0026#39;myuser\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;mypassword\u0026#39;} s = requests.session() # use Session to keep cookies around page = s.get(mysite) s.post(page.url, data=credentials) # page.url is the Siteminder login screen page = s.get(mysite) print(page.content) ","date":1496444825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496444825,"objectID":"651ed759d74822a81a6fa86a4a7907f3","permalink":"https://gliptak.github.io/post/python-requests-siteminder/","publishdate":"2017-06-02T19:07:05-04:00","relpermalink":"/post/python-requests-siteminder/","section":"post","summary":"While this below code is simple, it uses two important approaches:\n utilizes a Requests Session to keep Siteminder login cookies/headers it has a two step load, allowing to fill out the Siteminder form  import requests if __name__ == \u0026#34;__main__\u0026#34;: mysite = \u0026#39;http://mysite/\u0026#39; credentials = {\u0026#39;USER\u0026#39;: \u0026#39;myuser\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;mypassword\u0026#39;} s = requests.session() # use Session to keep cookies around page = s.get(mysite) s.post(page.url, data=credentials) # page.url is the Siteminder login screen page = s.","tags":["Python","Requests","Siteminder","SSO"],"title":"Login into a CA SSO/Siteminder protected site with Python Requests","type":"post"},{"authors":["Gábor Lipták"],"categories":[],"content":"When looking into AWS SimpleDB, a quick search didn\u0026rsquo;t return any short Python Boto3 examples. So I decided to post one. (As with any services you to subscribe to, running this code below might cost you money \u0026hellip;)\nfrom __future__ import print_function import boto3 def quote(string): return string.replace(\u0026#34;\u0026#39;\u0026#34;, \u0026#34;\u0026#39;\u0026#39;\u0026#34;).replace(\u0026#39;\u0026#34;\u0026#39;, \u0026#39;\u0026#34;\u0026#34;\u0026#39;).replace(\u0026#39;`\u0026#39;, \u0026#39;``\u0026#39;) def put_attributes(sdb, domain, id, color): response = sdb.put_attributes( DomainName=domain, ItemName=id, Attributes=[ { \u0026#39;Name\u0026#39;: \u0026#39;color\u0026#39;, \u0026#39;Value\u0026#39;: color, \u0026#39;Replace\u0026#39;: True }, ], ) print(response) if __name__ == \u0026#34;__main__\u0026#34;: domain = \u0026#34;TEST_DOMAIN\u0026#34; sdb = boto3.client(\u0026#39;sdb\u0026#39;) response = sdb.create_domain( DomainName=domain ) print(response) response = sdb.list_domains( ) print(\u0026#34;Current domains: %s\u0026#34; % response[\u0026#39;DomainNames\u0026#39;]) put_attributes(sdb, domain, \u0026#34;id1\u0026#34;, \u0026#34;red\u0026#34;) put_attributes(sdb, domain, \u0026#34;id2\u0026#34;, \u0026#34;redblue\u0026#34;) put_attributes(sdb, domain, \u0026#34;id3\u0026#34;, \u0026#34;blue\u0026#34;) response = sdb.select( SelectExpression=\u0026#39;select * from %swhere color like \u0026#34;%%%s%%\u0026#34;\u0026#39; % (domain, quote(\u0026#39;blue\u0026#39;)), ) print(response) response = sdb.delete_domain( DomainName=domain ) print(response) ","date":1487199115,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487199115,"objectID":"0e6f5bff746cfae857f68c2429d7be2f","permalink":"https://gliptak.github.io/post/simpledb-example/","publishdate":"2017-02-15T17:51:55-05:00","relpermalink":"/post/simpledb-example/","section":"post","summary":"When looking into AWS SimpleDB, a quick search didn\u0026rsquo;t return any short Python Boto3 examples. So I decided to post one. (As with any services you to subscribe to, running this code below might cost you money \u0026hellip;)\nfrom __future__ import print_function import boto3 def quote(string): return string.replace(\u0026#34;\u0026#39;\u0026#34;, \u0026#34;\u0026#39;\u0026#39;\u0026#34;).replace(\u0026#39;\u0026#34;\u0026#39;, \u0026#39;\u0026#34;\u0026#34;\u0026#39;).replace(\u0026#39;`\u0026#39;, \u0026#39;``\u0026#39;) def put_attributes(sdb, domain, id, color): response = sdb.put_attributes( DomainName=domain, ItemName=id, Attributes=[ { \u0026#39;Name\u0026#39;: \u0026#39;color\u0026#39;, \u0026#39;Value\u0026#39;: color, \u0026#39;Replace\u0026#39;: True }, ], ) print(response) if __name__ == \u0026#34;__main__\u0026#34;: domain = \u0026#34;TEST_DOMAIN\u0026#34; sdb = boto3.","tags":["AWS","Boto3"],"title":"AWS SimpleDB Boto3 Example","type":"post"},{"authors":null,"categories":null,"content":"","date":1482451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482451200,"objectID":"f260737f45d16625b8764cec25c908c0","permalink":"https://gliptak.github.io/project/jallele/","publishdate":"2016-12-23T00:00:00Z","relpermalink":"/project/jallele/","section":"project","summary":"JAllele is a Java mutation testing tool.","tags":null,"title":"JAllele","type":"project"},{"authors":null,"categories":null,"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"eec36d3e4e8d3fe47cb9eb4ff776eeda","permalink":"https://gliptak.github.io/project/go-a-perspective/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/project/go-a-perspective/","section":"project","summary":"Presentation on Go features anchoring them onto other languages like C, Java, Python, etc.","tags":null,"title":"Go - A Perspective","type":"project"}]